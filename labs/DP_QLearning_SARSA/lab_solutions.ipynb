{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reinforcement Learning - Practical Session 1\n",
    "\n",
    "\n",
    "## Review\n",
    "\n",
    "A Markov Decision Process (MDP) is defined as tuple $(S, A, P, r, \\gamma)$ where:\n",
    "* $S$ is the state space\n",
    "* $A$ is the action space \n",
    "* $P$ represents the transition probabilities, $P(s,a,s')$ is the probability of arriving at state $s'$ by taking action $a$ in state $s$\n",
    "* $r$ is the reward function such that $r(s,a,s')$ is the reward obtained by taking action $a$ in state $s$ and arriving at $s'$\n",
    "* $\\gamma$ is the discount factor\n",
    "\n",
    "A deterministic policy $\\pi$ is a mapping from $S$ to $A$: $\\pi(s)$ is the action to be taken at state $s$.\n",
    "\n",
    "The goal of an agent is to find the policy $\\pi$ that maximizes the expected sum of discounted rewards by following $\\pi$. The value of $\\pi$ is defined as\n",
    "\n",
    "$$\n",
    "V_\\pi(s) = E\\left[ \\sum_{t=0}^\\infty \\gamma^t r(S_t, A_t, S_{t+1}) | S_0 = s \\right]\n",
    "$$\n",
    "\n",
    "$V_\\pi(s)$ and the optimal value function, defined as $V^*(s) = \\max_\\pi V_\\pi(s)$, can be shown to satisfy the Bellman equations:\n",
    "\n",
    "$$\n",
    "V_\\pi(s) = \\sum_{s' \\in S}  P(s,\\pi(s),s')[r(s,\\pi(s),s') + \\gamma V_\\pi(s')]\n",
    "$$\n",
    "\n",
    "\n",
    "$$\n",
    "V^*(s) = \\max_{a\\in A} \\sum_{s' \\in S}  P(s,a,s')[r(s,a,s') + \\gamma V^*(s')]\n",
    "$$\n",
    "\n",
    "It is sometimes better to work with Q functions:\n",
    "\n",
    "$$\n",
    "Q_\\pi(s, a) = \\sum_{s' \\in S}  P(s,a,s')[r(s,a,s') + \\gamma  Q^*(s', \\pi(s')]\n",
    "$$\n",
    "\n",
    "\n",
    "$$\n",
    "Q^*(s, a) = \\sum_{s' \\in S}  P(s,a,s')[r(s,a,s') + \\gamma \\max_{a'} Q^*(s', a')]\n",
    "$$\n",
    "\n",
    "such that $V_\\pi(s) = Q_\\pi(s, \\pi(s))$ and $V^*(s) = \\max_a Q^*(s, a)$.\n",
    "\n",
    "\n",
    "### Using value iteration to compute an optimal policy\n",
    "If the reward function and the transition probabilities are known (and the state and action spaces are not very large), we can use dynamic programming methods to compute $V^*(s)$. Value iteration is one way to do that.\n",
    "\n",
    "\n",
    "#####  Value iteration to compute $V^*(s)$\n",
    "$$\n",
    "T^* Q(s,a) = \\sum_{s'}P(s'|s,a)[ r(s, a, s') + \\gamma \\max_{a'} Q(s', a')]   \\\\\n",
    "$$\n",
    "\n",
    "\n",
    "* For any $Q_0$, let $Q_n = T^* Q_{n-1}$. \n",
    "* We have $\\lim_{n\\to\\infty}Q_n = Q^*$ and $Q^* = T^* Q^*$\n",
    "\n",
    "\n",
    "##### Finding the optimal policy from $V^\\pi(s)$\n",
    "\n",
    "The optimal policy $\\pi^*$ can be computed as\n",
    "\n",
    "$$\n",
    "\\pi^*(s) \\in \\arg\\max_{a\\in A} Q^*(s, a) =  \\arg\\max_{a\\in A} \\sum_{s' \\in S}  P(s,a,s')[r(s,a,s') + \\gamma V^*(s')]\n",
    "$$\n",
    "\n",
    "###  Q-Learning and SARSA \n",
    "\n",
    "When the reward function and the transition probabilities are *unknown*, we cannot use dynamic programming to find the optimal value function. Q-Learning and SARSA are stochastic approximation algorithms that allows us to estimate the value function by using only samples from the environment.\n",
    "\n",
    "#####  Q-learning\n",
    "\n",
    "The Q-Learning algorithm allows us to estimate the optimal Q function using only trajectories from the MDP obtained by following some exploration policy. \n",
    "\n",
    "Q-learning with $\\varepsilon$-greedy exploration does the following update at time $t$:\n",
    "\n",
    "1. In state $s_t$, take action $a_t$  such that $a_t$ is random with probability $\\varepsilon$ and $a_t \\in \\arg\\max_a \\hat{Q}_t(s_t,a) $ with probability $1-\\varepsilon$;\n",
    "2. Observe $s_{t+1}$ and reward $r_t$;\n",
    "3. Compute $\\delta_t = r_t + \\gamma \\max_a \\hat{Q}_t(s_{t+1}, a) - \\hat{Q}_t(s_t, a_t)$;\n",
    "4. Update $\\hat{Q}_{t+1}(s, a) = \\hat{Q}_t(s, a) + \\alpha_t(s,a)\\delta_t\\mathbb{1}\\{s=s_t, a=a_t\\}  $\n",
    "\n",
    "\n",
    "##### SARSA\n",
    "\n",
    "SARSA is similar to Q-learning, but it is an *on-policy* algorithm: it follows a (stochastic) policy $\\pi_Q$ and updates its estimate towards the value of this policy. One possible choice is:\n",
    "\n",
    "$$\n",
    "\\pi_Q(a|s) = \\frac{ \\exp(\\tau^{-1}Q(s,a))  }{\\sum_{a'}\\exp(\\tau^{-1}Q(s,a')) }\n",
    "$$\n",
    "where $\\tau$ is a \"temperature\" parameter: when $\\tau$ approaches 0, $\\pi_Q(a|s)$ approaches the greedy (deterministic) policy $a \\in \\arg\\max_{a'}Q(s,a')$.\n",
    "\n",
    "At each time $t$, SARSA keeps an estimate $\\hat{Q}_t$ of the true Q function and uses $\\pi_{\\hat{Q}_t}(a|s)$ to choose the action $a_t$. If $\\tau \\to 0$ with a proper rate as $t \\to \\infty$, $\\hat{Q}_t$ converges to $Q$ and $\\pi_{\\hat{Q}_t}(a|s)$ converges to the optimal policy $\\pi^*$. \n",
    "\n",
    "The SARSA update at time $t$ is done as follows:\n",
    "\n",
    "1. In state $s_t$, take action $a_t \\sim \\pi_{\\hat{Q}_t}(a|s_t)$ ;\n",
    "2. Observe $s_{t+1}$ and reward $r_t$;\n",
    "3. Sample the next action $a_{t+1} \\sim \\pi_{\\hat{Q}_t}(a|s_{t+1})$;\n",
    "4. Compute $\\delta_t = r_t + \\gamma \\hat{Q}_t(s_{t+1}, a_{t+1}) - \\hat{Q}_t(s_t, a_t)$\n",
    "5. Update $\\hat{Q}_{t+1}(s, a) = \\hat{Q}_t(s, a) + \\alpha_t(s,a)\\delta_t\\mathbb{1}\\{s=s_t, a=a_t\\}$\n",
    "\n",
    "## Goals\n",
    "\n",
    "Your goal is to implement Value Iteration, Q-Learning and SARSA for the [Frozen Lake](https://gym.openai.com/envs/FrozenLake-v0/) environment.\n",
    "\n",
    "* In exercise 1, you will implement the Bellman operators $T^\\pi$ and $T^*$ and verify their properties.\n",
    "* In exercise 2, you will implement value iteration\n",
    "* In exercises 3 and 4, you will implement Q-Learning and SARSA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'test_env'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-64c355bd7763>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mfrozen_lake\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFrozenLake\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtest_env\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mToyEnv1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'test_env'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.special import softmax # for SARSA\n",
    "import matplotlib.pyplot as plt\n",
    "from frozen_lake import FrozenLake\n",
    "from test_env import ToyEnv1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FrozenLake environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set of states: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n",
      "Set of actions: [0, 1, 2, 3]\n",
      "Number of states:  16\n",
      "Number of actions:  4\n",
      "P has shape:  (16, 4, 16)\n",
      "discount factor:  0.95\n",
      "\n",
      "initial state:  0\n",
      "reward at (s=1, a=3,s'=2):  0.0\n",
      "\n",
      "random policy =  [0 0 1 0 1 1 0 2 2 1 2 2 1 3 1 1]\n",
      "(s, a, s', r):\n",
      "0 0 0 0.0\n",
      "0 0 4 0.0\n",
      "4 1 8 0.0\n",
      "8 2 9 0.0\n",
      "\n",
      "(S: starting point, safe) (F: frozen surface, safe) (H: hole, fall to your doom) (G: goal, where the frisbee is located)\n",
      "=================\n",
      "SFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "=================\n",
      "Current state 9\n"
     ]
    }
   ],
   "source": [
    "# Creating an instance of FrozenLake\n",
    "# --- If deterministic=False, transitions are stochastic. Try both cases!\n",
    "env = FrozenLake(gamma=0.95, deterministic=False) \n",
    "# Small environment for debugging\n",
    "# env = ToyEnv1(gamma=0.95)\n",
    "\n",
    "# Useful attributes\n",
    "print(\"Set of states:\", env.states)\n",
    "print(\"Set of actions:\", env.actions)\n",
    "print(\"Number of states: \", env.Ns)\n",
    "print(\"Number of actions: \", env.Na)\n",
    "print(\"P has shape: \", env.P.shape)  # P[s, a, s'] = env.P[s, a, s']\n",
    "print(\"discount factor: \", env.gamma)\n",
    "print(\"\")\n",
    "\n",
    "# Usefult methods\n",
    "state = env.reset() # get initial state\n",
    "print(\"initial state: \", state)\n",
    "print(\"reward at (s=1, a=3,s'=2): \", env.reward_func(1,3,2))\n",
    "print(\"\")\n",
    "\n",
    "# A random policy\n",
    "policy = np.random.randint(env.Na, size = (env.Ns,))\n",
    "print(\"random policy = \", policy)\n",
    "\n",
    "# Interacting with the environment\n",
    "print(\"(s, a, s', r):\")\n",
    "for time in range(4):\n",
    "    action = policy[state]\n",
    "    next_state, reward, done, info = env.step(action)\n",
    "    print(state, action, next_state, reward)\n",
    "    if done:\n",
    "        break\n",
    "    state = next_state\n",
    "print(\"\")\n",
    "\n",
    "# Visualizing the environment\n",
    "try:\n",
    "    env.render()\n",
    "except:\n",
    "    pass # render not available"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1: Bellman operator\n",
    "\n",
    "1. Write a function that takes an environment and a state-action value function $Q$ as input and returns the Bellman optimality operator applied to $Q$, $T^* Q$ and the greedy policy with respect to $Q$.\n",
    "3. Let $Q_1$ and $Q_2$ be state-action value functions. Verify the contraction property:  $\\Vert T^* Q_1 - T^* Q_2\\Vert \\leq \\gamma ||Q_1 - Q_2||$, where $||V|| = \\max_{s,a} |Q(s,a)|$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------\n",
    "# Solution to 1.\n",
    "# --------------\n",
    "def bellman_operator(Q, env):\n",
    "    TQ = np.zeros((env.Ns, env.Na))\n",
    "    greedy_policy = np.zeros(env.Ns)\n",
    "    for s in env.states:\n",
    "        for a in env.actions:\n",
    "            prob = env.P[s, a, :]\n",
    "            rewards = np.array([float(env.reward_func(s,a, s_)) for s_ in env.states])\n",
    "            TQ[s,a] = np.sum( prob*(rewards + env.gamma*Q.max(axis=1))  )\n",
    "\n",
    "    argmax = np.argmax(TQ, axis = 1)\n",
    "    greedy_policy = argmax\n",
    "    \n",
    "    return TQ, greedy_policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contraction of Bellman operator: \n",
      "0.4705311455663862\n",
      "0.5018592496431588\n",
      "0.5212830535495661\n",
      "0.3741195746613664\n",
      "0.4245633315232942\n",
      "0.46726741407590683\n",
      "0.45440986862852795\n",
      "0.5346380124717157\n",
      "0.4707176218584958\n",
      "0.31085018712299795\n",
      "0.507503872009211\n",
      "0.36163134057140556\n",
      "0.4700491406450985\n",
      "0.3259317884415954\n",
      "0.3893022279254102\n"
     ]
    }
   ],
   "source": [
    "# --------------\n",
    "# Solution to 2.\n",
    "# --------------\n",
    "n_simulations = 15\n",
    "\n",
    "print(\"Contraction of Bellman operator: \")\n",
    "for ii in range(n_simulations):\n",
    "    Q1 = np.random.randn(env.Ns, env.Na)\n",
    "    Q2 = np.random.randn(env.Ns, env.Na)\n",
    "\n",
    "    # Contraction of Bellman operator\n",
    "    contraction = np.abs(bellman_operator(Q1, env)[0] - bellman_operator(Q2, env)[0]).max() / np.abs(Q1-Q2).max()\n",
    "    print(contraction)\n",
    "    assert contraction <= env.gamma + 1e-12 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2: Value iteration\n",
    "\n",
    "1. (Optimal Value function) Write a function that takes as input an initial state-action value function `Q0` and an environment `env` and returns a vector `Q` such that $||T^* Q -  Q ||_\\infty \\leq \\varepsilon $ and the greedy policy with respect to $Q$.\n",
    "2. Test the convergence of the function you implemented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------\n",
    "# Solution to 1.\n",
    "# --------------\n",
    "def value_iteration(Q0, env, epsilon=1e-5):\n",
    "    \"\"\"\n",
    "    Finding the optimal value function. To be done!\n",
    "    \"\"\"\n",
    "    it = 1\n",
    "    Q = Q0\n",
    "    while True:\n",
    "        TQ, greedy_policy = bellman_operator(Q, env)\n",
    "\n",
    "        err = np.abs(TQ-Q).max() \n",
    "        if err < epsilon:\n",
    "            return TQ, greedy_policy\n",
    "\n",
    "        Q = TQ\n",
    "        it += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "norm of T(Q) - Q =  9.185378004872291e-07\n",
      "(S: starting point, safe) (F: frozen surface, safe) (H: hole, fall to your doom) (G: goal, where the frisbee is located)\n",
      "=================\n",
      "SFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "=================\n",
      "Current state 0\n",
      "None\n",
      "(S: starting point, safe) (F: frozen surface, safe) (H: hole, fall to your doom) (G: goal, where the frisbee is located)\n",
      "=================\n",
      "SFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "=================\n",
      "Current state 5\n",
      "None\n",
      "[0 3 0 3 0 0 0 0 3 1 0 0 0 2 1 0]\n"
     ]
    }
   ],
   "source": [
    "# --------------\n",
    "# Solution to 2.\n",
    "# --------------\n",
    "epsilon = 1e-6\n",
    "Q0 = np.zeros((env.Ns, env.Na))\n",
    "\n",
    "Q, greedy_policy = value_iteration(Q0, env, epsilon)\n",
    "err = np.abs(Q - bellman_operator(Q, env)[0]).max()\n",
    "print(\"norm of T(Q) - Q = \", err)\n",
    "assert err <= epsilon\n",
    "\n",
    "env.reset()\n",
    "print(env.render())\n",
    "env.step(1)\n",
    "env.step(1)\n",
    "env.step(2)\n",
    "env.step(1)\n",
    "env.step(2)\n",
    "env.step(2)\n",
    "print(env.render())\n",
    "print(greedy_policy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 3: Q-Learning\n",
    "\n",
    "Implement Q-learning and test its convergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------\n",
    "# Q-Learning implementation\n",
    "# ------------------------------\n",
    "\n",
    "class QLearning:\n",
    "    \"\"\"\n",
    "    Implements Q-learning algorithm with epsilon-greedy exploration\n",
    "\n",
    "    If learning_rate is None; alpha(x,a) = 1/max(1, N(s,a))**alpha\n",
    "    \"\"\"\n",
    "    def __init__(self, env, gamma, alpha=0.8, learning_rate=None, min_learning_rate=0.5, epsilon=1.0, epsilon_decay=0.995,\n",
    "                 epsilon_min=0.5, seed=42):\n",
    "        self.env = env\n",
    "        self.gamma = gamma\n",
    "        self.alpha = alpha\n",
    "        self.learning_rate = learning_rate\n",
    "        self.min_learning_rate = min_learning_rate\n",
    "        self.epsilon = epsilon\n",
    "        self.epsilon_decay = epsilon_decay\n",
    "        self.epsilon_min = epsilon_min\n",
    "        self.Q = np.zeros((env.Ns, env.Na))\n",
    "        self.Nsa = np.zeros((env.Ns, env.Na))\n",
    "        self.state = env.reset()\n",
    "        self.RS = np.random.RandomState(seed)\n",
    "\n",
    "    def get_delta(self, r, x, a, y, done):\n",
    "        \"\"\"\n",
    "        :param r: reward\n",
    "        :param x: current state\n",
    "        :param a: current action\n",
    "        :param y: next state\n",
    "        :param done:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        max_q_y_a = self.Q[y, :].max()\n",
    "        q_x_a = self.Q[x, a]\n",
    "\n",
    "        return r + self.gamma*max_q_y_a - q_x_a\n",
    "\n",
    "    def get_learning_rate(self, s, a):\n",
    "        if self.learning_rate is None:\n",
    "            return max(1.0/max(1.0, self.Nsa[s, a])**self.alpha, self.min_learning_rate)\n",
    "        else:\n",
    "            return max(self.learning_rate, self.min_learning_rate)\n",
    "\n",
    "    def get_action(self, state):\n",
    "        if self.RS.uniform(0, 1) < self.epsilon:\n",
    "            # explore\n",
    "            return np.random.choice(self.env.actions)\n",
    "        else:\n",
    "            # exploit\n",
    "            a = self.Q[state, :].argmax()\n",
    "            return a\n",
    "\n",
    "    def step(self):\n",
    "        # Current state\n",
    "        x = self.env.state\n",
    "\n",
    "        # Choose action\n",
    "        a = self.get_action(x)\n",
    "\n",
    "        # Learning rate\n",
    "        alpha = self.get_learning_rate(x, a)\n",
    "\n",
    "        # Take step\n",
    "        observation, reward, done, info = self.env.step(a)\n",
    "        y = observation\n",
    "        r = reward\n",
    "        delta = self.get_delta(r, x, a, y, done)\n",
    "\n",
    "        # Update\n",
    "        self.Q[x, a] = self.Q[x, a] + alpha*delta\n",
    "\n",
    "        self.Nsa[x, a] += 1\n",
    "        \n",
    "        if done:\n",
    "            # print(x, observation, reward)\n",
    "            self.epsilon = max(self.epsilon*self.epsilon_decay, self.epsilon_min)\n",
    "            self.env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S: starting point, safe) (F: frozen surface, safe) (H: hole, fall to your doom) (G: goal, where the frisbee is located)\n",
      "=================\n",
      "SFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "=================\n",
      "Current state 0\n",
      "None\n",
      "optimal policy:  [0 3 0 3 0 0 0 0 3 1 0 0 0 2 1 0]\n",
      "est policy: [1 3 2 0 1 0 0 0 2 1 0 0 0 2 1 0]\n",
      "0\n",
      "true:  [3.60941723 3.44655723 3.44655723 3.26608565]\n",
      "est:  [5.34320499 5.7414725  5.48019212 5.2881939 ]\n",
      "----------------------------\n",
      "1\n",
      "true:  [2.12310376 2.11500048 1.95214047 3.09512236]\n",
      "est:  [4.99630358 4.66240341 4.73225856 6.18865108]\n",
      "----------------------------\n",
      "2\n",
      "true:  [3.06953292 2.93698449 2.9288812  2.79161063]\n",
      "est:  [5.00917582 4.80280208 5.14941486 4.69912168]\n",
      "----------------------------\n",
      "3\n",
      "true:  [1.81148875 1.81148875 1.67894031 2.65095891]\n",
      "est:  [4.29116691 2.02691649 2.93610339 4.23681543]\n",
      "----------------------------\n",
      "4\n",
      "true:  [4.17932748 3.0363456  2.85587402 2.46643535]\n",
      "est:  [5.79778049 6.67827016 5.67412385 3.86326785]\n",
      "----------------------------\n",
      "5\n",
      "true:  [0. 0. 0. 0.]\n",
      "est:  [0. 0. 0. 0.]\n",
      "----------------------------\n",
      "6\n",
      "true:  [3.52860814 2.55658954 3.52860814 0.97201859]\n",
      "est:  [3.0640725  2.58018172 1.96108394 0.14749567]\n",
      "----------------------------\n",
      "7\n",
      "true:  [0. 0. 0. 0.]\n",
      "est:  [0. 0. 0. 0.]\n",
      "----------------------------\n",
      "8\n",
      "true:  [3.0363456  4.08568034 3.69624167 5.4091338 ]\n",
      "est:  [4.22714933 7.06109491 9.24046075 6.36164676]\n",
      "----------------------------\n",
      "9\n",
      "true:  [4.9364266  7.49301615 5.78012402 4.26948168]\n",
      "est:  [ 5.23329381 10.38754347  7.6203909   7.26970844]\n",
      "----------------------------\n",
      "10\n",
      "true:  [8.07344135 6.9560489  5.70065314 3.49018066]\n",
      "est:  [14.18485871  6.03354763  8.51772398  8.26491775]\n",
      "----------------------------\n",
      "11\n",
      "true:  [0. 0. 0. 0.]\n",
      "est:  [0. 0. 0. 0.]\n",
      "----------------------------\n",
      "12\n",
      "true:  [0. 0. 0. 0.]\n",
      "est:  [0. 0. 0. 0.]\n",
      "----------------------------\n",
      "13\n",
      "true:  [ 5.59632268  7.80679516 10.17958337  6.9560489 ]\n",
      "est:  [ 8.39017874  9.10856951 14.36783005  7.44604917]\n",
      "----------------------------\n",
      "14\n",
      "true:  [10.36338471 14.47345571 13.80651078 12.44678456]\n",
      "est:  [13.88951706 18.99375369 13.769119   13.23693065]\n",
      "----------------------------\n",
      "15\n",
      "true:  [19.99998163 19.99998163 19.99998163 19.99998163]\n",
      "est:  [19.97168082 19.96926567 19.96633066 19.96974608]\n",
      "----------------------------\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ---------------------------\n",
    "# Convergence of Q-Learning\n",
    "# ---------------------------\n",
    "\n",
    "# Number of Q learning iterations\n",
    "n_steps = int(1e5)  \n",
    "#n_steps = 10\n",
    "\n",
    "# Get optimal value function and its greedy policy\n",
    "Q0 = np.zeros((env.Ns, env.Na))\n",
    "Q_opt, pi_opt = value_iteration(Q0, env, epsilon=1e-6)\n",
    "\n",
    "# Create qlearning object\n",
    "qlearning = QLearning(env, gamma=env.gamma)\n",
    "\n",
    "# Iterate\n",
    "tt = 0\n",
    "Q_est = np.zeros((n_steps, env.Ns, env.Na))\n",
    "while tt < n_steps:\n",
    "    qlearning.step()\n",
    "    # Store estimate of Q*\n",
    "    Q_est[tt, :, :] = qlearning.Q\n",
    "    tt +=1\n",
    "    \n",
    "\n",
    "# Compute greedy policy (with estimated Q)\n",
    "greedy_policy = np.argmax(qlearning.Q, axis=1)\n",
    "\n",
    "# Plot\n",
    "diff = np.abs(Q_est - Q_opt).mean(axis=(1,2))\n",
    "plt.plot(diff)\n",
    "plt.xlabel('iteration')\n",
    "plt.ylabel('Error')\n",
    "plt.title(\"Q-learning convergence\")\n",
    "\n",
    "print(env.render())\n",
    "print(\"optimal policy: \", pi_opt)\n",
    "print(\"est policy:\", greedy_policy)\n",
    "\n",
    "for state in env.states:\n",
    "    print(state)\n",
    "    print(\"true: \", Q_opt[state, :])\n",
    "    print(\"est: \", Q_est[-1,state, :])\n",
    "    print(\"----------------------------\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 4: SARSA\n",
    "\n",
    "Implement SARSA and test its convergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------\n",
    "# SARSA implementation\n",
    "# ------------------------------\n",
    "\n",
    "class Sarsa:\n",
    "    \"\"\"\n",
    "    Implements SARSA algorithm.\n",
    "\n",
    "    If learning_rate is None; alpha(x,a) = 1/max(1, N(s,a))**alpha\n",
    "    \"\"\"\n",
    "    def __init__(self, env, gamma, alpha=0.8, learning_rate=None, min_learning_rate=0.01, tau=1.0, tau_decay=0.9995,\n",
    "                 tau_min=0.1, seed=42):\n",
    "        self.env = env\n",
    "        self.gamma = gamma\n",
    "        self.alpha = alpha\n",
    "        self.learning_rate = learning_rate\n",
    "        self.min_learning_rate = min_learning_rate\n",
    "        self.tau = tau\n",
    "        self.tau_decay = tau_decay\n",
    "        self.tau_min = tau_min\n",
    "        self.Q = np.zeros((env.Ns, env.Na))\n",
    "        self.Nsa = np.zeros((env.Ns, env.Na))\n",
    "        self.state = env.reset()\n",
    "        self.RS = np.random.RandomState(seed)\n",
    "\n",
    "    def get_delta(self, r, x, a, y, next_a, done):\n",
    "        \"\"\"\n",
    "        :param r: reward\n",
    "        :param x: current state\n",
    "        :param a: current action\n",
    "        :param y: next state\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        q_y_a = self.Q[y, next_a]\n",
    "        q_x_a = self.Q[x, a]\n",
    "\n",
    "        return r + self.gamma*q_y_a - q_x_a\n",
    "\n",
    "    def get_learning_rate(self, s, a):\n",
    "        if self.learning_rate is None:\n",
    "            return max(1.0/max(1.0, self.Nsa[s, a])**self.alpha, self.min_learning_rate)\n",
    "        else:\n",
    "            return max(self.learning_rate, self.min_learning_rate)\n",
    "\n",
    "    def get_action(self, state):\n",
    "        q = self.Q[state, :]\n",
    "        prob = softmax(q/self.tau)\n",
    "        a = np.random.choice(self.env.actions, p=prob)\n",
    "        return a\n",
    "\n",
    "    def step(self):\n",
    "        # Current state\n",
    "        x = self.env.state\n",
    "\n",
    "        # Choose action\n",
    "        a = self.get_action(x)\n",
    "\n",
    "        # Learning rate\n",
    "        alpha = self.get_learning_rate(x, a)\n",
    "\n",
    "        # Take step\n",
    "        observation, reward, done, info = self.env.step(a)\n",
    "        y = observation\n",
    "        r = reward\n",
    "        next_a = self.get_action(y)\n",
    "        delta = self.get_delta(r, x, a, y, next_a, done)\n",
    "\n",
    "        # Update\n",
    "        self.Q[x, a] = self.Q[x, a] + alpha*delta\n",
    "\n",
    "        self.Nsa[x, a] += 1\n",
    "\n",
    "        if done:\n",
    "            # print(x, observation, reward)\n",
    "            self.tau = max(self.tau*self.tau_decay, self.tau_min)\n",
    "            self.env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S: starting point, safe) (F: frozen surface, safe) (H: hole, fall to your doom) (G: goal, where the frisbee is located)\n",
      "=================\n",
      "SFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "=================\n",
      "Current state 2\n",
      "None\n",
      "optimal policy:  [0 3 0 3 0 0 0 0 3 1 0 0 0 2 1 0]\n",
      "est policy: [0 3 0 3 0 0 2 0 3 1 0 0 0 1 2 0]\n",
      "0\n",
      "true:  [3.60941723 3.44655723 3.44655723 3.26608565]\n",
      "est:  [1.24380036 1.2200373  1.22706206 0.60478605]\n",
      "----------------------------\n",
      "1\n",
      "true:  [2.12310376 2.11500048 1.95214047 3.09512236]\n",
      "est:  [0.23469874 0.41958533 0.23795037 1.13475526]\n",
      "----------------------------\n",
      "2\n",
      "true:  [3.06953292 2.93698449 2.9288812  2.79161063]\n",
      "est:  [1.21332779 0.41455334 0.56356686 0.08584844]\n",
      "----------------------------\n",
      "3\n",
      "true:  [1.81148875 1.81148875 1.67894031 2.65095891]\n",
      "est:  [0.12433847 0.10210099 0.02752937 0.15095817]\n",
      "----------------------------\n",
      "4\n",
      "true:  [4.17932748 3.0363456  2.85587402 2.46643535]\n",
      "est:  [1.47227564 0.76084765 0.35407898 0.09163911]\n",
      "----------------------------\n",
      "5\n",
      "true:  [0. 0. 0. 0.]\n",
      "est:  [0. 0. 0. 0.]\n",
      "----------------------------\n",
      "6\n",
      "true:  [3.52860814 2.55658954 3.52860814 0.97201859]\n",
      "est:  [0.58980115 0.63121802 1.37148261 0.01917414]\n",
      "----------------------------\n",
      "7\n",
      "true:  [0. 0. 0. 0.]\n",
      "est:  [0. 0. 0. 0.]\n",
      "----------------------------\n",
      "8\n",
      "true:  [3.0363456  4.08568034 3.69624167 5.4091338 ]\n",
      "est:  [0.07365838 0.41215804 0.28925273 2.01809682]\n",
      "----------------------------\n",
      "9\n",
      "true:  [4.9364266  7.49301615 5.78012402 4.26948168]\n",
      "est:  [0.21082637 2.90847529 0.81986316 0.39473989]\n",
      "----------------------------\n",
      "10\n",
      "true:  [8.07344135 6.9560489  5.70065314 3.49018066]\n",
      "est:  [3.65818819 0.71335455 0.9323738  0.10839888]\n",
      "----------------------------\n",
      "11\n",
      "true:  [0. 0. 0. 0.]\n",
      "est:  [0. 0. 0. 0.]\n",
      "----------------------------\n",
      "12\n",
      "true:  [0. 0. 0. 0.]\n",
      "est:  [0. 0. 0. 0.]\n",
      "----------------------------\n",
      "13\n",
      "true:  [ 5.59632268  7.80679516 10.17958337  6.9560489 ]\n",
      "est:  [0.06051295 3.47073209 1.35985687 0.86332558]\n",
      "----------------------------\n",
      "14\n",
      "true:  [10.36338471 14.47345571 13.80651078 12.44678456]\n",
      "est:  [0.32999081 2.57049161 7.44650089 0.59067695]\n",
      "----------------------------\n",
      "15\n",
      "true:  [19.99998163 19.99998163 19.99998163 19.99998163]\n",
      "est:  [11.63800356  0.          0.          1.        ]\n",
      "----------------------------\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ---------------------------\n",
    "# Convergence of SARSA\n",
    "# ---------------------------\n",
    "\n",
    "# Create SARSA object\n",
    "sarsa = Sarsa(env, gamma=env.gamma)\n",
    "\n",
    "# Iterate\n",
    "tt = 0\n",
    "Q_est = np.zeros((n_steps, env.Ns, env.Na))\n",
    "while tt < n_steps:\n",
    "    sarsa.step()\n",
    "    # Store estimate of Q*\n",
    "    Q_est[tt, :, :] = sarsa.Q\n",
    "    tt +=1\n",
    "\n",
    "# Compute greedy policy (with estimated Q)\n",
    "greedy_policy = np.argmax(sarsa.Q, axis=1)\n",
    "\n",
    "# Plot\n",
    "diff = np.abs(Q_est - Q_opt).mean(axis=(1,2))\n",
    "plt.plot(diff)\n",
    "plt.xlabel('iteration')\n",
    "plt.ylabel('Error')\n",
    "plt.title(\"SARSA\")\n",
    "\n",
    "\n",
    "print(env.render())\n",
    "print(\"optimal policy: \", pi_opt)\n",
    "print(\"est policy:\", greedy_policy)\n",
    "\n",
    "for state in env.states:\n",
    "    print(state)\n",
    "    print(\"true: \", Q_opt[state, :])\n",
    "    print(\"est: \", Q_est[-1,state, :])\n",
    "    print(\"----------------------------\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
