{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reinforcement Learning - Practical Session 1\n",
    "\n",
    "\n",
    "## Review\n",
    "\n",
    "A Markov Decision Process (MDP) is defined as tuple $(S, A, P, r, \\gamma)$ where:\n",
    "* $S$ is the state space\n",
    "* $A$ is the action space \n",
    "* $P$ represents the transition probabilities, $P(s,a,s')$ is the probability of arriving at state $s'$ by taking action $a$ in state $s$\n",
    "* $r$ is the reward function such that $r(s,a,s')$ is the reward obtained by taking action $a$ in state $s$ and arriving at $s'$\n",
    "* $\\gamma$ is the discount factor\n",
    "\n",
    "A deterministic policy $\\pi$ is a mapping from $S$ to $A$: $\\pi(s)$ is the action to be taken at state $s$.\n",
    "\n",
    "The goal of an agent is to find the policy $\\pi$ that maximizes the expected sum of discounted rewards by following $\\pi$. The value of $\\pi$ is defined as\n",
    "\n",
    "$$\n",
    "V_\\pi(s) = E\\left[ \\sum_{t=0}^\\infty \\gamma^t r(S_t, A_t, S_{t+1}) | S_0 = s \\right]\n",
    "$$\n",
    "\n",
    "$V_\\pi(s)$ and the optimal value function, defined as $V^*(s) = \\max_\\pi V_\\pi(s)$, can be shown to satisfy the Bellman equations:\n",
    "\n",
    "$$\n",
    "V_\\pi(s) = \\sum_{s' \\in S}  P(s,\\pi(s),s')[r(s,\\pi(s),s') + \\gamma V_\\pi(s')]\n",
    "$$\n",
    "\n",
    "\n",
    "$$\n",
    "V^*(s) = \\max_{a\\in A} \\sum_{s' \\in S}  P(s,a,s')[r(s,a,s') + \\gamma V^*(s')]\n",
    "$$\n",
    "\n",
    "It is sometimes better to work with Q functions:\n",
    "\n",
    "$$\n",
    "Q_\\pi(s, a) = \\sum_{s' \\in S}  P(s,a,s')[r(s,a,s') + \\gamma  Q^*(s', \\pi(s')]\n",
    "$$\n",
    "\n",
    "\n",
    "$$\n",
    "Q^*(s, a) = \\sum_{s' \\in S}  P(s,a,s')[r(s,a,s') + \\gamma \\max_{a'} Q^*(s', a')]\n",
    "$$\n",
    "\n",
    "such that $V_\\pi(s) = Q_\\pi(s, \\pi(s))$ and $V^*(s) = \\max_a Q^*(s, a)$.\n",
    "\n",
    "\n",
    "### Using value iteration to compute an optimal policy\n",
    "If the reward function and the transition probabilities are known (and the state and action spaces are not very large), we can use dynamic programming methods to compute $V^*(s)$. Value iteration is one way to do that.\n",
    "\n",
    "\n",
    "#####  Value iteration to compute $V^*(s)$\n",
    "$$\n",
    "T^* Q(s,a) = \\sum_{s'}P(s'|s,a)[ r(s, a, s') + \\gamma \\max_{a'} Q(s', a')]   \\\\\n",
    "$$\n",
    "\n",
    "\n",
    "* For any $Q_0$, let $Q_n = T^* Q_{n-1}$. \n",
    "* We have $\\lim_{n\\to\\infty}Q_n = Q^*$ and $Q^* = T^* Q^*$\n",
    "\n",
    "\n",
    "##### Finding the optimal policy from $V^\\pi(s)$\n",
    "\n",
    "The optimal policy $\\pi^*$ can be computed as\n",
    "\n",
    "$$\n",
    "\\pi^*(s) \\in \\arg\\max_{a\\in A} Q^*(s, a) =  \\arg\\max_{a\\in A} \\sum_{s' \\in S}  P(s,a,s')[r(s,a,s') + \\gamma V^*(s')]\n",
    "$$\n",
    "\n",
    "###  Q-Learning and SARSA \n",
    "\n",
    "When the reward function and the transition probabilities are *unknown*, we cannot use dynamic programming to find the optimal value function. Q-Learning and SARSA are stochastic approximation algorithms that allows us to estimate the value function by using only samples from the environment.\n",
    "\n",
    "#####  Q-learning\n",
    "\n",
    "The Q-Learning algorithm allows us to estimate the optimal Q function using only trajectories from the MDP obtained by following some exploration policy. \n",
    "\n",
    "Q-learning with $\\varepsilon$-greedy exploration does the following update at time $t$:\n",
    "\n",
    "1. In state $s_t$, take action $a_t$  such that $a_t$ is random with probability $\\varepsilon$ and $a_t \\in \\arg\\max_a \\hat{Q}_t(s_t,a) $ with probability $1-\\varepsilon$;\n",
    "2. Observe $s_{t+1}$ and reward $r_t$;\n",
    "3. Compute $\\delta_t = r_t + \\gamma \\max_a \\hat{Q}_t(s_{t+1}, a) - \\hat{Q}_t(s_t, a_t)$;\n",
    "4. Update $\\hat{Q}_{t+1}(s, a) = \\hat{Q}_t(s, a) + \\alpha_t(s,a)\\delta_t\\mathbb{1}\\{s=s_t, a=a_t\\}  $\n",
    "\n",
    "\n",
    "##### SARSA\n",
    "\n",
    "SARSA is similar to Q-learning, but it is an *on-policy* algorithm: it follows a (stochastic) policy $\\pi_Q$ and updates its estimate towards the value of this policy. One possible choice is:\n",
    "\n",
    "$$\n",
    "\\pi_Q(a|s) = \\frac{ \\exp(\\tau^{-1}Q(s,a))  }{\\sum_{a'}\\exp(\\tau^{-1}Q(s,a')) }\n",
    "$$\n",
    "where $\\tau$ is a \"temperature\" parameter: when $\\tau$ approaches 0, $\\pi_Q(a|s)$ approaches the greedy (deterministic) policy $a \\in \\arg\\max_{a'}Q(s,a')$.\n",
    "\n",
    "At each time $t$, SARSA keeps an estimate $\\hat{Q}_t$ of the true Q function and uses $\\pi_{\\hat{Q}_t}(a|s)$ to choose the action $a_t$. If $\\tau \\to 0$ with a proper rate as $t \\to \\infty$, $\\hat{Q}_t$ converges to $Q$ and $\\pi_{\\hat{Q}_t}(a|s)$ converges to the optimal policy $\\pi^*$. \n",
    "\n",
    "The SARSA update at time $t$ is done as follows:\n",
    "\n",
    "1. In state $s_t$, take action $a_t \\sim \\pi_{\\hat{Q}_t}(a|s_t)$ ;\n",
    "2. Observe $s_{t+1}$ and reward $r_t$;\n",
    "3. Sample the next action $a_{t+1} \\sim \\pi_{\\hat{Q}_t}(a|s_{t+1})$;\n",
    "4. Compute $\\delta_t = r_t + \\gamma \\hat{Q}_t(s_{t+1}, a_{t+1}) - \\hat{Q}_t(s_t, a_t)$\n",
    "5. Update $\\hat{Q}_{t+1}(s, a) = \\hat{Q}_t(s, a) + \\alpha_t(s,a)\\delta_t\\mathbb{1}\\{s=s_t, a=a_t\\}$\n",
    "\n",
    "## Goals\n",
    "\n",
    "Your goal is to implement Value Iteration, Q-Learning and SARSA for the [Frozen Lake](https://gym.openai.com/envs/FrozenLake-v0/) environment.\n",
    "\n",
    "* In exercise 1, you will implement the Bellman operators $T^\\pi$ and $T^*$ and verify their properties.\n",
    "* In exercise 2, you will implement value iteration\n",
    "* In exercises 3 and 4, you will implement Q-Learning and SARSA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, './rlss2019-hands-on/utils')\n",
    "# If using the Docker image, replace by:\n",
    "# sys.path.insert(0, '../utils')\n",
    "\n",
    "import numpy as np\n",
    "from scipy.special import softmax # for SARSA\n",
    "import matplotlib.pyplot as plt\n",
    "from frozen_lake import FrozenLake\n",
    "from test_env import ToyEnv1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FrozenLake environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set of states: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n",
      "Set of actions: [0, 1, 2, 3]\n",
      "Number of states:  16\n",
      "Number of actions:  4\n",
      "P has shape:  (16, 4, 16)\n",
      "discount factor:  0.95\n",
      "\n",
      "initial state:  0\n",
      "reward at (s=1, a=3,s'=2):  0.0\n",
      "\n",
      "random policy =  [1 3 1 2 2 3 3 2 3 1 2 3 3 0 1 2]\n",
      "(s, a, s', r):\n",
      "0 1 1 0.0\n",
      "1 3 2 0.0\n",
      "2 1 6 0.0\n",
      "6 3 5 0.0\n",
      "\n",
      "(S: starting point, safe) (F: frozen surface, safe) (H: hole, fall to your doom) (G: goal, where the frisbee is located)\n",
      "=================\n",
      "SFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "=================\n",
      "Current state 5\n"
     ]
    }
   ],
   "source": [
    "# Creating an instance of FrozenLake\n",
    "# --- If deterministic=False, transitions are stochastic. Try both cases!\n",
    "env = FrozenLake(gamma=0.95, deterministic=False) \n",
    "# Small environment for debugging\n",
    "# env = ToyEnv1(gamma=0.95)\n",
    "\n",
    "# Useful attributes\n",
    "print(\"Set of states:\", env.states)\n",
    "print(\"Set of actions:\", env.actions)\n",
    "print(\"Number of states: \", env.Ns)\n",
    "print(\"Number of actions: \", env.Na)\n",
    "print(\"P has shape: \", env.P.shape)  # P[s, a, s'] = env.P[s, a, s']\n",
    "print(\"discount factor: \", env.gamma)\n",
    "print(\"\")\n",
    "\n",
    "# Usefult methods\n",
    "state = env.reset() # get initial state\n",
    "print(\"initial state: \", state)\n",
    "print(\"reward at (s=1, a=3,s'=2): \", env.reward_func(1,3,2))\n",
    "print(\"\")\n",
    "\n",
    "# A random policy\n",
    "policy = np.random.randint(env.Na, size = (env.Ns,))\n",
    "print(\"random policy = \", policy)\n",
    "\n",
    "# Interacting with the environment\n",
    "print(\"(s, a, s', r):\")\n",
    "for time in range(4):\n",
    "    action = policy[state]\n",
    "    next_state, reward, done, info = env.step(action)\n",
    "    print(state, action, next_state, reward)\n",
    "    if done:\n",
    "        break\n",
    "    state = next_state\n",
    "print(\"\")\n",
    "\n",
    "# Visualizing the environment\n",
    "try:\n",
    "    env.render()\n",
    "except:\n",
    "    pass # render not available"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1: Bellman operator\n",
    "\n",
    "1. Write a function that takes an environment and a state-action value function $Q$ as input and returns the Bellman optimality operator applied to $Q$, $T^* Q$ and the greedy policy with respect to $Q$.\n",
    "3. Let $Q_1$ and $Q_2$ be state-action value functions. Verify the contraction property:  $\\Vert T^* Q_1 - T^* Q_2\\Vert \\leq \\gamma ||Q_1 - Q_2||$, where $||V|| = \\max_{s,a} |Q(s,a)|$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------\n",
    "# Solution to 1.\n",
    "# --------------\n",
    "def bellman_operator(Q, env):\n",
    "    TQ = np.zeros((env.Ns, env.Na))\n",
    "    greedy_policy = np.zeros(env.Ns)\n",
    "    for s in env.states:\n",
    "        for a in env.actions:\n",
    "            prob = env.P[s, a, :]\n",
    "            rewards = np.array([float(env.reward_func(s,a, s_)) for s_ in env.states])\n",
    "            TQ[s,a] = np.sum( prob*(rewards + env.gamma*Q.max(axis=1))  )\n",
    "\n",
    "    argmax = np.argmax(TQ, axis = 1)\n",
    "    greedy_policy = argmax\n",
    "    \n",
    "    return TQ, greedy_policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contraction of Bellman operator: \n",
      "0.2387380747077634\n",
      "0.7058803181672457\n",
      "0.3998498903216087\n",
      "0.4662696523274021\n",
      "0.8135261129105308\n",
      "0.3437191283174684\n",
      "0.5006864885572608\n",
      "0.4796806969113801\n",
      "0.420020753857982\n",
      "0.784934176255539\n",
      "0.4055267054024433\n",
      "0.2790982106499737\n",
      "0.4719957260323857\n",
      "0.45400061978622064\n",
      "0.32487460839435867\n"
     ]
    }
   ],
   "source": [
    "# --------------\n",
    "# Solution to 2.\n",
    "# --------------\n",
    "n_simulations = 15\n",
    "\n",
    "print(\"Contraction of Bellman operator: \")\n",
    "for ii in range(n_simulations):\n",
    "    Q1 = np.random.randn(env.Ns, env.Na)\n",
    "    Q2 = np.random.randn(env.Ns, env.Na)\n",
    "\n",
    "    # Contraction of Bellman operator\n",
    "    contraction = np.abs(bellman_operator(Q1, env)[0] - bellman_operator(Q2, env)[0]).max() / np.abs(Q1-Q2).max()\n",
    "    print(contraction)\n",
    "    assert contraction <= env.gamma + 1e-12 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2: Value iteration\n",
    "\n",
    "1. (Optimal Value function) Write a function that takes as input an initial state-action value function `Q0` and an environment `env` and returns a vector `Q` such that $||T^* Q -  Q ||_\\infty \\leq \\varepsilon $ and the greedy policy with respect to $Q$.\n",
    "2. Test the convergence of the function you implemented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------\n",
    "# Solution to 1.\n",
    "# --------------\n",
    "def value_iteration(Q0, env, epsilon=1e-5):\n",
    "    \"\"\"\n",
    "    Finding the optimal value function. To be done!\n",
    "    \"\"\"\n",
    "    it = 1\n",
    "    Q = Q0\n",
    "    while True:\n",
    "        TQ, greedy_policy = bellman_operator(Q, env)\n",
    "\n",
    "        err = np.abs(TQ-Q).max() \n",
    "        if err < epsilon:\n",
    "            return TQ, greedy_policy\n",
    "\n",
    "        Q = TQ\n",
    "        it += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "norm of T(Q) - Q =  9.185378004872291e-07\n",
      "(S: starting point, safe) (F: frozen surface, safe) (H: hole, fall to your doom) (G: goal, where the frisbee is located)\n",
      "=================\n",
      "SFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "=================\n",
      "Current state 0\n",
      "None\n",
      "(S: starting point, safe) (F: frozen surface, safe) (H: hole, fall to your doom) (G: goal, where the frisbee is located)\n",
      "=================\n",
      "SFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "=================\n",
      "Current state 5\n",
      "None\n",
      "[0 3 0 3 0 0 0 0 3 1 0 0 0 2 1 0]\n"
     ]
    }
   ],
   "source": [
    "# --------------\n",
    "# Solution to 2.\n",
    "# --------------\n",
    "epsilon = 1e-6\n",
    "Q0 = np.zeros((env.Ns, env.Na))\n",
    "\n",
    "Q, greedy_policy = value_iteration(Q0, env, epsilon)\n",
    "err = np.abs(Q - bellman_operator(Q, env)[0]).max()\n",
    "print(\"norm of T(Q) - Q = \", err)\n",
    "assert err <= epsilon\n",
    "\n",
    "env.reset()\n",
    "print(env.render())\n",
    "env.step(1)\n",
    "env.step(1)\n",
    "env.step(2)\n",
    "env.step(1)\n",
    "env.step(2)\n",
    "env.step(2)\n",
    "print(env.render())\n",
    "print(greedy_policy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 3: Q-Learning\n",
    "\n",
    "Implement Q-learning and test its convergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------\n",
    "# Q-Learning implementation\n",
    "# ------------------------------\n",
    "\n",
    "class QLearning:\n",
    "    \"\"\"\n",
    "    Implements Q-learning algorithm with epsilon-greedy exploration\n",
    "\n",
    "    If learning_rate is None; alpha(x,a) = 1/max(1, N(s,a))**alpha\n",
    "    \"\"\"\n",
    "    def __init__(self, env, gamma, alpha=0.8, learning_rate=None, min_learning_rate=0.5, epsilon=1.0, epsilon_decay=0.995,\n",
    "                 epsilon_min=0.5, seed=42):\n",
    "        self.env = env\n",
    "        self.gamma = gamma\n",
    "        self.alpha = alpha\n",
    "        self.learning_rate = learning_rate\n",
    "        self.min_learning_rate = min_learning_rate\n",
    "        self.epsilon = epsilon\n",
    "        self.epsilon_decay = epsilon_decay\n",
    "        self.epsilon_min = epsilon_min\n",
    "        self.Q = np.zeros((env.Ns, env.Na))\n",
    "        self.Nsa = np.zeros((env.Ns, env.Na))\n",
    "        self.state = env.reset()\n",
    "        self.RS = np.random.RandomState(seed)\n",
    "\n",
    "    def get_delta(self, r, x, a, y, done):\n",
    "        \"\"\"\n",
    "        :param r: reward\n",
    "        :param x: current state\n",
    "        :param a: current action\n",
    "        :param y: next state\n",
    "        :param done:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        max_q_y_a = self.Q[y, :].max()\n",
    "        q_x_a = self.Q[x, a]\n",
    "\n",
    "        return r + self.gamma*max_q_y_a - q_x_a\n",
    "\n",
    "    def get_learning_rate(self, s, a):\n",
    "        if self.learning_rate is None:\n",
    "            return max(1.0/max(1.0, self.Nsa[s, a])**self.alpha, self.min_learning_rate)\n",
    "        else:\n",
    "            return max(self.learning_rate, self.min_learning_rate)\n",
    "\n",
    "    def get_action(self, state):\n",
    "        if self.RS.uniform(0, 1) < self.epsilon:\n",
    "            # explore\n",
    "            return np.random.choice(self.env.actions)\n",
    "        else:\n",
    "            # exploit\n",
    "            a = self.Q[state, :].argmax()\n",
    "            return a\n",
    "\n",
    "    def step(self):\n",
    "        # Current state\n",
    "        x = self.env.state\n",
    "\n",
    "        # Choose action\n",
    "        a = self.get_action(x)\n",
    "\n",
    "        # Learning rate\n",
    "        alpha = self.get_learning_rate(x, a)\n",
    "\n",
    "        # Take step\n",
    "        observation, reward, done, info = self.env.step(a)\n",
    "        y = observation\n",
    "        r = reward\n",
    "        delta = self.get_delta(r, x, a, y, done)\n",
    "\n",
    "        # Update\n",
    "        self.Q[x, a] = self.Q[x, a] + alpha*delta\n",
    "\n",
    "        self.Nsa[x, a] += 1\n",
    "        \n",
    "        if done:\n",
    "            # print(x, observation, reward)\n",
    "            self.epsilon = max(self.epsilon*self.epsilon_decay, self.epsilon_min)\n",
    "            self.env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S: starting point, safe) (F: frozen surface, safe) (H: hole, fall to your doom) (G: goal, where the frisbee is located)\n",
      "=================\n",
      "SFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "=================\n",
      "Current state 3\n",
      "None\n",
      "optimal policy:  [0 3 0 3 0 0 0 0 3 1 0 0 0 2 1 0]\n",
      "est policy: [2 2 2 3 2 0 2 0 1 1 0 0 0 1 2 3]\n",
      "0\n",
      "true:  [3.60941723 3.44655723 3.44655723 3.26608565]\n",
      "est:  [3.29974592 2.66640266 3.38030579 2.59156345]\n",
      "----------------------------\n",
      "1\n",
      "true:  [2.12310376 2.11500048 1.95214047 3.09512236]\n",
      "est:  [0.4903708  1.82688877 3.38194579 3.361802  ]\n",
      "----------------------------\n",
      "2\n",
      "true:  [3.06953292 2.93698449 2.9288812  2.79161063]\n",
      "est:  [2.89550294 2.34448735 3.53199442 2.642874  ]\n",
      "----------------------------\n",
      "3\n",
      "true:  [1.81148875 1.81148875 1.67894031 2.65095891]\n",
      "est:  [2.00669541 1.12624599 2.0286035  2.22611083]\n",
      "----------------------------\n",
      "4\n",
      "true:  [4.17932748 3.0363456  2.85587402 2.46643535]\n",
      "est:  [3.56552625 0.34145883 3.65320408 2.94093564]\n",
      "----------------------------\n",
      "5\n",
      "true:  [0. 0. 0. 0.]\n",
      "est:  [0. 0. 0. 0.]\n",
      "----------------------------\n",
      "6\n",
      "true:  [3.52860814 2.55658954 3.52860814 0.97201859]\n",
      "est:  [1.16916445 0.35091343 8.66603264 0.40034723]\n",
      "----------------------------\n",
      "7\n",
      "true:  [0. 0. 0. 0.]\n",
      "est:  [0. 0. 0. 0.]\n",
      "----------------------------\n",
      "8\n",
      "true:  [3.0363456  4.08568034 3.69624167 5.4091338 ]\n",
      "est:  [2.03623405 7.27143484 2.27271499 4.37346957]\n",
      "----------------------------\n",
      "9\n",
      "true:  [4.9364266  7.49301615 5.78012402 4.26948168]\n",
      "est:  [2.01558431 8.11505746 0.8213347  4.94453532]\n",
      "----------------------------\n",
      "10\n",
      "true:  [8.07344135 6.9560489  5.70065314 3.49018066]\n",
      "est:  [14.94637372  2.39397637  0.22656857  1.96573155]\n",
      "----------------------------\n",
      "11\n",
      "true:  [0. 0. 0. 0.]\n",
      "est:  [0. 0. 0. 0.]\n",
      "----------------------------\n",
      "12\n",
      "true:  [0. 0. 0. 0.]\n",
      "est:  [0. 0. 0. 0.]\n",
      "----------------------------\n",
      "13\n",
      "true:  [ 5.59632268  7.80679516 10.17958337  6.9560489 ]\n",
      "est:  [ 3.74496774 11.79748855  7.60449941  7.81080517]\n",
      "----------------------------\n",
      "14\n",
      "true:  [10.36338471 14.47345571 13.80651078 12.44678456]\n",
      "est:  [ 9.5499232   8.71280423 18.36894914  8.02175062]\n",
      "----------------------------\n",
      "15\n",
      "true:  [19.99998163 19.99998163 19.99998163 19.99998163]\n",
      "est:  [19.98334465 19.97933923 19.98417528 19.98663664]\n",
      "----------------------------\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ---------------------------\n",
    "# Convergence of Q-Learning\n",
    "# ---------------------------\n",
    "\n",
    "# Number of Q learning iterations\n",
    "n_steps = int(1e5)  \n",
    "#n_steps = 10\n",
    "\n",
    "# Get optimal value function and its greedy policy\n",
    "Q0 = np.zeros((env.Ns, env.Na))\n",
    "Q_opt, pi_opt = value_iteration(Q0, env, epsilon=1e-6)\n",
    "\n",
    "# Create qlearning object\n",
    "qlearning = QLearning(env, gamma=env.gamma)\n",
    "\n",
    "# Iterate\n",
    "tt = 0\n",
    "Q_est = np.zeros((n_steps, env.Ns, env.Na))\n",
    "while tt < n_steps:\n",
    "    qlearning.step()\n",
    "    # Store estimate of Q*\n",
    "    Q_est[tt, :, :] = qlearning.Q\n",
    "    tt +=1\n",
    "    \n",
    "\n",
    "# Compute greedy policy (with estimated Q)\n",
    "greedy_policy = np.argmax(qlearning.Q, axis=1)\n",
    "\n",
    "# Plot\n",
    "diff = np.abs(Q_est - Q_opt).mean(axis=(1,2))\n",
    "plt.plot(diff)\n",
    "plt.xlabel('iteration')\n",
    "plt.ylabel('Error')\n",
    "plt.title(\"Q-learning convergence\")\n",
    "\n",
    "print(env.render())\n",
    "print(\"optimal policy: \", pi_opt)\n",
    "print(\"est policy:\", greedy_policy)\n",
    "\n",
    "for state in env.states:\n",
    "    print(state)\n",
    "    print(\"true: \", Q_opt[state, :])\n",
    "    print(\"est: \", Q_est[-1,state, :])\n",
    "    print(\"----------------------------\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 4: SARSA\n",
    "\n",
    "Implement SARSA and test its convergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------\n",
    "# SARSA implementation\n",
    "# ------------------------------\n",
    "\n",
    "class Sarsa:\n",
    "    \"\"\"\n",
    "    Implements SARSA algorithm.\n",
    "\n",
    "    If learning_rate is None; alpha(x,a) = 1/max(1, N(s,a))**alpha\n",
    "    \"\"\"\n",
    "    def __init__(self, env, gamma, alpha=0.8, learning_rate=None, min_learning_rate=0.01, tau=1.0, tau_decay=0.9995,\n",
    "                 tau_min=0.1, seed=42):\n",
    "        self.env = env\n",
    "        self.gamma = gamma\n",
    "        self.alpha = alpha\n",
    "        self.learning_rate = learning_rate\n",
    "        self.min_learning_rate = min_learning_rate\n",
    "        self.tau = tau\n",
    "        self.tau_decay = tau_decay\n",
    "        self.tau_min = tau_min\n",
    "        self.Q = np.zeros((env.Ns, env.Na))\n",
    "        self.Nsa = np.zeros((env.Ns, env.Na))\n",
    "        self.state = env.reset()\n",
    "        self.RS = np.random.RandomState(seed)\n",
    "\n",
    "    def get_delta(self, r, x, a, y, next_a, done):\n",
    "        \"\"\"\n",
    "        :param r: reward\n",
    "        :param x: current state\n",
    "        :param a: current action\n",
    "        :param y: next state\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        q_y_a = self.Q[y, next_a]\n",
    "        q_x_a = self.Q[x, a]\n",
    "\n",
    "        return r + self.gamma*q_y_a - q_x_a\n",
    "\n",
    "    def get_learning_rate(self, s, a):\n",
    "        if self.learning_rate is None:\n",
    "            return max(1.0/max(1.0, self.Nsa[s, a])**self.alpha, self.min_learning_rate)\n",
    "        else:\n",
    "            return max(self.learning_rate, self.min_learning_rate)\n",
    "\n",
    "    def get_action(self, state):\n",
    "        q = self.Q[state, :]\n",
    "        prob = softmax(q/self.tau)\n",
    "        a = np.random.choice(self.env.actions, p=prob)\n",
    "        return a\n",
    "\n",
    "    def step(self):\n",
    "        # Current state\n",
    "        x = self.env.state\n",
    "\n",
    "        # Choose action\n",
    "        a = self.get_action(x)\n",
    "\n",
    "        # Learning rate\n",
    "        alpha = self.get_learning_rate(x, a)\n",
    "\n",
    "        # Take step\n",
    "        observation, reward, done, info = self.env.step(a)\n",
    "        y = observation\n",
    "        r = reward\n",
    "        next_a = self.get_action(y)\n",
    "        delta = self.get_delta(r, x, a, y, next_a, done)\n",
    "\n",
    "        # Update\n",
    "        self.Q[x, a] = self.Q[x, a] + alpha*delta\n",
    "\n",
    "        self.Nsa[x, a] += 1\n",
    "\n",
    "        if done:\n",
    "            # print(x, observation, reward)\n",
    "            self.tau = max(self.tau*self.tau_decay, self.tau_min)\n",
    "            self.env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S: starting point, safe) (F: frozen surface, safe) (H: hole, fall to your doom) (G: goal, where the frisbee is located)\n",
      "=================\n",
      "SFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "=================\n",
      "Current state 0\n",
      "None\n",
      "optimal policy:  [0 3 0 3 0 0 0 0 3 1 0 0 0 2 1 0]\n",
      "est policy: [0 3 0 1 0 0 2 0 3 1 0 0 0 2 2 0]\n",
      "0\n",
      "true:  [3.60941723 3.44655723 3.44655723 3.26608565]\n",
      "est:  [2.03830029 0.4372978  0.47763139 0.22405372]\n",
      "----------------------------\n",
      "1\n",
      "true:  [2.12310376 2.11500048 1.95214047 3.09512236]\n",
      "est:  [0.15161177 0.18567621 0.13940514 1.22767602]\n",
      "----------------------------\n",
      "2\n",
      "true:  [3.06953292 2.93698449 2.9288812  2.79161063]\n",
      "est:  [1.32119772 0.43463336 0.39749597 0.08934681]\n",
      "----------------------------\n",
      "3\n",
      "true:  [1.81148875 1.81148875 1.67894031 2.65095891]\n",
      "est:  [0.10712983 0.10935055 0.03015528 0.10478587]\n",
      "----------------------------\n",
      "4\n",
      "true:  [4.17932748 3.0363456  2.85587402 2.46643535]\n",
      "est:  [2.35446001 0.49071524 0.3866371  0.11538586]\n",
      "----------------------------\n",
      "5\n",
      "true:  [0. 0. 0. 0.]\n",
      "est:  [0. 0. 0. 0.]\n",
      "----------------------------\n",
      "6\n",
      "true:  [3.52860814 2.55658954 3.52860814 0.97201859]\n",
      "est:  [0.63652468 0.61280994 1.78513294 0.0265874 ]\n",
      "----------------------------\n",
      "7\n",
      "true:  [0. 0. 0. 0.]\n",
      "est:  [0. 0. 0. 0.]\n",
      "----------------------------\n",
      "8\n",
      "true:  [3.0363456  4.08568034 3.69624167 5.4091338 ]\n",
      "est:  [0.07385516 0.6744821  0.44541384 3.13784334]\n",
      "----------------------------\n",
      "9\n",
      "true:  [4.9364266  7.49301615 5.78012402 4.26948168]\n",
      "est:  [0.56837704 4.33684608 1.30465679 0.42384724]\n",
      "----------------------------\n",
      "10\n",
      "true:  [8.07344135 6.9560489  5.70065314 3.49018066]\n",
      "est:  [4.60929132 1.26523104 0.37187899 0.03021934]\n",
      "----------------------------\n",
      "11\n",
      "true:  [0. 0. 0. 0.]\n",
      "est:  [0. 0. 0. 0.]\n",
      "----------------------------\n",
      "12\n",
      "true:  [0. 0. 0. 0.]\n",
      "est:  [0. 0. 0. 0.]\n",
      "----------------------------\n",
      "13\n",
      "true:  [ 5.59632268  7.80679516 10.17958337  6.9560489 ]\n",
      "est:  [0.5833845  1.28897118 5.8348075  0.94986987]\n",
      "----------------------------\n",
      "14\n",
      "true:  [10.36338471 14.47345571 13.80651078 12.44678456]\n",
      "est:  [0.47718292 0.37687058 8.5545438  2.92341263]\n",
      "----------------------------\n",
      "15\n",
      "true:  [19.99998163 19.99998163 19.99998163 19.99998163]\n",
      "est:  [13.71156613  1.          1.78851815  3.56413763]\n",
      "----------------------------\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ---------------------------\n",
    "# Convergence of SARSA\n",
    "# ---------------------------\n",
    "\n",
    "# Create SARSA object\n",
    "sarsa = Sarsa(env, gamma=env.gamma)\n",
    "\n",
    "# Iterate\n",
    "tt = 0\n",
    "Q_est = np.zeros((n_steps, env.Ns, env.Na))\n",
    "while tt < n_steps:\n",
    "    sarsa.step()\n",
    "    # Store estimate of Q*\n",
    "    Q_est[tt, :, :] = sarsa.Q\n",
    "    tt +=1\n",
    "\n",
    "# Compute greedy policy (with estimated Q)\n",
    "greedy_policy = np.argmax(sarsa.Q, axis=1)\n",
    "\n",
    "# Plot\n",
    "diff = np.abs(Q_est - Q_opt).mean(axis=(1,2))\n",
    "plt.plot(diff)\n",
    "plt.xlabel('iteration')\n",
    "plt.ylabel('Error')\n",
    "plt.title(\"SARSA\")\n",
    "\n",
    "\n",
    "print(env.render())\n",
    "print(\"optimal policy: \", pi_opt)\n",
    "print(\"est policy:\", greedy_policy)\n",
    "\n",
    "for state in env.states:\n",
    "    print(state)\n",
    "    print(\"true: \", Q_opt[state, :])\n",
    "    print(\"est: \", Q_est[-1,state, :])\n",
    "    print(\"----------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
